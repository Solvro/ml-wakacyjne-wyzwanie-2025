{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b57bc7b8"
      },
      "source": [
        "## Klasyfikacja ręcznie pisanych liczb - MNIST\n",
        "\n",
        "Po wykonaniu poprzedniego zadania zleceniodawca znów zadzwonił do Ciebie z kolejnym zadaniem. Okazuje się, że nie wszystkie informacje trafiły do zbioru Tytanic. Brakowało w nim między innymi informacji o pokojach w których mieszkali pasażerowie. Wszystkie informacje o miejscu spania były bowiem zapisane odręcznie na kartkach. Tajemniczy  więc zlecił Ci nowe zadanie... **Stworzenie konwolucyjnej sieci neuronowej rozpoznającej ręcznie pisane cyfry.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### Twoim celem będzie jest wytrenowanie modelu widzenia komputerowego (CNN) do klasyfikacji każdej ręcznie pisanej liczby z jak najlepszą dokładnością.\n",
        "\n",
        "Poniżej znajdziesz pytania, które mogą być pomocne w zadaniu:\n",
        "\n",
        "- Co mój model robi i w jaki sposób?\n",
        "- Na czym skupia się mój model?\n",
        "- Jakie liczby mój model myli? Dlaczego?\n",
        "- Jak uodpornić mój model?\n",
        "- Jaki wynik klasyfikacji możemy uznać za *dobry*?\n",
        "\n",
        "\n",
        "Wymagania:\n",
        "- Wypisz obserwacje z pierwszego zadania, które pomogą Ci w tym. Co było przydatne, a co okazało się bezużyteczne?\n",
        "- Stwórz baseline, czyli dla porównania sprawdź jak z zadaniem radzi sobie zwykła sieć (nie musi być na wszystkich próbkach - zajmie to długo)\n",
        "- W badaniach użyj wybranych metryk. Wybór uzasadnij.\n",
        "- Spróbuj dobrać strukture sieci (szerokość i wysokość) i sprawdź jaki ma wpływ na dokładność\n",
        "- Ćwiczenie: zmień liczbę kanałów/warstw, dodaj BatchNorm, spróbuj zwiększyć/zmniejszyć dropout.\n",
        "- Wypisz wnioski.\n",
        "- Korzystaj z `PyTorch` (`torch, torchvision`)\n",
        "\n",
        "Niezmiennie, zadbaj o czytelność kodu i nazewnictwo zmiennych. Jeśli jakiś wycinek kodu się powtarza, to wyodrębnij go do funkcji. Postaraj się zamieszczać swoje wnioski w postaci komentarza `Markdown`."
      ],
      "metadata": {
        "id": "F91TE041THEf"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "262b3307",
        "outputId": "7286b469-c86b-47a3-ee2f-d2ac37c653e5"
      },
      "source": [
        "# ładowanie zbioru danych\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "\n",
        "plt.imshow(x_train[0], cmap='gray')\n",
        "plt.title(f\"Przykład cyfry: {y_train[0]}\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Rozwiazanie:**"
      ],
      "metadata": {
        "id": "eBq5bK3HQyUg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Punkt 1 - wnioski z poprzednich zadań:**\n",
        "\n",
        "\n",
        "1. **Przygotowanie danych** – Titanic pokazał, że dane muszą być przygotowane\n",
        "2. **Baseline** - Titanic nauczył, że należy zaczynać od prostego modelu żeby mieć punkt odniesienia i porównanie do naszego.\n",
        "3. **Overfitting** - tu też trzeba uważać, żeby sieć się nie „nauczyła na pamięć”"
      ],
      "metadata": {
        "id": "8_LdqzhWZvlE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Punkt 2 - Setup:**"
      ],
      "metadata": {
        "id": "oMNZwuhhiLeb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Przekopiowane z notatnika z lekkimi zmianami\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, random_split, Dataset, DataLoader, TensorDataset\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import itertools\n",
        "import time\n",
        "import os\n",
        "import random\n",
        "\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Używane urządzenie: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbLAaMT7qZpk",
        "outputId": "61d1d6a5-d086-406e-98be-9d8e008fb82e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Używane urządzenie: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Teraz wykonamy normalizacje danych testowych i treningowych + przekonwertujemy je do tensora PyTorch"
      ],
      "metadata": {
        "id": "7f2FxOCVtNNS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Konwersja danych treningowych do tensora PyTorch + normalizacja (0-1 zamiast 0-255)\n",
        "x_train_t = torch.tensor(x_train, dtype=torch.float32) / 255.0\n",
        "y_train_t = torch.tensor(y_train, dtype=torch.long)\n",
        "\n",
        "x_test_t = torch.tensor(x_test, dtype=torch.float32) / 255.0\n",
        "y_test_t = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "print(f\"Rozmiar zbioru treningowego: {x_train_t.shape}\")\n",
        "print(f\"Rozmiar zbioru testowego: {x_test_t.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2nsD2K-iNqT",
        "outputId": "7d87d915-e27f-4ef0-e1ba-8e7a8143d4ad"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rozmiar zbioru treningowego: torch.Size([60000, 28, 28])\n",
            "Rozmiar zbioru testowego: torch.Size([10000, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chciałem trooche sie pobawić samemu w obróbkę danych i troche nie kumam dlaczego tutaj nie ma tego color channelu, który powinien być równy jeden. W każdym razie dodaję go poniżej, ponieważ CNN oczekuje [batch, channel, H, W]"
      ],
      "metadata": {
        "id": "-ihp1axf2J6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_t = x_train_t.unsqueeze(1)  # (60000, 1, 28, 28)\n",
        "x_test_t = x_test_t.unsqueeze(1)    # (10000, 1, 28, 28)\n",
        "\n",
        "print(f\"Poprawiony rozmiar zbioru treningowego: {x_train_t.shape}\")\n",
        "print(f\"Poprawiony rozmiar zbioru testowego: {x_test_t.shape}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "# Stworzenie Datasetów i DataLoaderów\n",
        "train_dataset = TensorDataset(x_train_t, y_train_t)\n",
        "test_dataset = TensorDataset(x_test_t, y_test_t)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True) # przy trenowaniu miesza kolejność próbek (ważne dla lepszego uczenia).\n",
        "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False) # przy testowaniu nie ma sensu mieszać, testujemy całość „po kolei”.\n",
        "\n",
        "print(\"Rozmiar batcha treningowego:\", next(iter(train_loader))[0].shape)\n",
        "print(\"Rozmiar batcha testowego:\", next(iter(test_loader))[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wJuKCn_tfHa",
        "outputId": "cde000f6-9e0e-4451-f4be-92f2ad179a75"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Poprawiony rozmiar zbioru treningowego: torch.Size([60000, 1, 28, 28])\n",
            "Poprawiony rozmiar zbioru testowego: torch.Size([10000, 1, 28, 28])\n",
            "\n",
            "\n",
            "Rozmiar batcha treningowego: torch.Size([64, 1, 28, 28])\n",
            "Rozmiar batcha testowego: torch.Size([1000, 1, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Funkcja treningowa:"
      ],
      "metadata": {
        "id": "eAeXpz4LyVZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_train(model, loader):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for xb, yb in loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(xb)\n",
        "        loss = criterion(pred, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "def model_test(model, loader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            pred = model(xb)\n",
        "            correct += (pred.argmax(1) == yb).sum().item()\n",
        "            total += yb.size(0)\n",
        "    return correct / total"
      ],
      "metadata": {
        "id": "GoH2xPy-yW9l"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Punkty 3 - Baseline MLP:**"
      ],
      "metadata": {
        "id": "xZyUvDXKqPnW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Baseline"
      ],
      "metadata": {
        "id": "ST6ttOpBnSFF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(784, 256)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Inicjalizacja\n",
        "model_mlp = MLP().to(device)\n",
        "optimizer = optim.Adam(model_mlp.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "przXOzVmnTD_"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trening MLP:"
      ],
      "metadata": {
        "id": "w7wqG4NSofWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10):\n",
        "    loss = model_train(model_mlp, train_loader)\n",
        "    acc = model_test(model_mlp, test_loader)\n",
        "    print(f\"Epoch {epoch+1}: loss={loss:.4f}, acc={acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuRmShxGofJS",
        "outputId": "c228d2df-10f7-49c2-8536-e8387b969a54"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: loss=0.2872, acc=0.9595\n",
            "Epoch 2: loss=0.1096, acc=0.9708\n",
            "Epoch 3: loss=0.0727, acc=0.9760\n",
            "Epoch 4: loss=0.0538, acc=0.9798\n",
            "Epoch 5: loss=0.0382, acc=0.9780\n",
            "Epoch 6: loss=0.0307, acc=0.9798\n",
            "Epoch 7: loss=0.0267, acc=0.9787\n",
            "Epoch 8: loss=0.0216, acc=0.9783\n",
            "Epoch 9: loss=0.0176, acc=0.9743\n",
            "Epoch 10: loss=0.0165, acc=0.9810\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Punkt 4 - CNN:**\n"
      ],
      "metadata": {
        "id": "Ji2Op9_PppNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc2 = nn.Linear(32 * 7 * 7, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Inicjalizacja\n",
        "model_cnn = CNN().to(device)\n",
        "optimizer = optim.Adam(model_cnn.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "GlPbfM89puvW"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trening CNN:"
      ],
      "metadata": {
        "id": "vVJeXHNBp0xd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10):\n",
        "    loss = model_train(model_cnn, train_loader)\n",
        "    acc = model_test(model_cnn, test_loader)\n",
        "    print(f\"Epoch {epoch+1}: loss={loss:.4f}, acc={acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsMHPVo6pzRf",
        "outputId": "1c1606d0-43ce-4514-ad5e-c60ab9b03f19"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: loss=0.2501, acc=0.9805\n",
            "Epoch 2: loss=0.0670, acc=0.9869\n",
            "Epoch 3: loss=0.0500, acc=0.9837\n",
            "Epoch 4: loss=0.0408, acc=0.9875\n",
            "Epoch 5: loss=0.0346, acc=0.9852\n",
            "Epoch 6: loss=0.0290, acc=0.9878\n",
            "Epoch 7: loss=0.0255, acc=0.9878\n",
            "Epoch 8: loss=0.0222, acc=0.9878\n",
            "Epoch 9: loss=0.0193, acc=0.9889\n",
            "Epoch 10: loss=0.0171, acc=0.9890\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Punkt 5 - eksperyment CNN z BatchNorm i dropout:**"
      ],
      "metadata": {
        "id": "b_RQQIXi4lfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_exp(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(CNN_exp, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(16)  # Normalizuje aktywacje - stabilizuje trening\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "        self.dropout1 = nn.Dropout(0.25)  # Wyłącza 25% neuronów - zapobiega overfittingowi\n",
        "\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        self.dropout2 = nn.Dropout(0.25)\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc2 = nn.Linear(32 * 7 * 7, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Inicjalizacja\n",
        "model_cnn_exp = CNN_exp().to(device)\n",
        "optimizer = optim.Adam(model_cnn_exp.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "CnCxdc1O8KVu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(5):\n",
        "    loss = model_train(model_cnn_exp, train_loader)\n",
        "    acc = model_test(model_cnn_exp, test_loader)\n",
        "    print(f\"Epoch {epoch+1}: loss={loss:.4f}, acc={acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-SmszUV_b76",
        "outputId": "f61aa905-6f84-4780-aa72-dd02d76b7252"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: loss=0.2135, acc=0.9775\n",
            "Epoch 2: loss=0.0893, acc=0.9854\n",
            "Epoch 3: loss=0.0735, acc=0.9873\n",
            "Epoch 4: loss=0.0645, acc=0.9876\n",
            "Epoch 5: loss=0.0604, acc=0.9873\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Wnioski:**\n",
        "\n",
        "1. Baseline (MLP) gorzej niż CNN.  \n",
        "2. CNN – ~99% dokładności naturalny wybór dla obrazów.  \n",
        "3. CNN z BatchNorm i dropout jeszcze lepszy wynik\n",
        "\n",
        "W praktyce – prosty CNN wystarcza na MNIST, ale na bardziej rozbudowanych datasetach może architektura i regularizacja mają dużo większe znaczenie.\n"
      ],
      "metadata": {
        "id": "CQmjpNR5CWxC"
      }
    }
  ]
}