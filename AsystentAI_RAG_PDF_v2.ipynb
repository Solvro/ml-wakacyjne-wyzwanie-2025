{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import bibliotek"
      ],
      "metadata": {
        "id": "DCv_xSu1qf84"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "utUYNHrpkaUr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b3bc429-df95-4bff-c145-783b11b1e701"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.12/dist-packages (6.0.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.3.29)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.75)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.23)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.34.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.9)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "from pathlib import Path\n",
        "!pip install langchain sentence-transformers faiss-cpu pypdf transformers torch langchain-community\n",
        "from langchain.document_loaders import PyPDFLoader, TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, AutoModelForSeq2SeqLM\n",
        "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.schema import Document\n",
        "import re\n",
        "import os\n",
        "import torch\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "os.environ[\"HF_TOKEN\"] = \"TWÓJ_HF_TOKEN\"\n",
        "!pip install transformers torch langchain faiss-cpu sentence-transformers --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linki do tych artykułów:\n",
        "\n",
        "- Samoloty pasażerskie najczęściej wykorzystywane do przewozów – studium przypadku Boeninga i Airbusa : tendencje rozwoju\n",
        "- Bezpieczeństwo przewozu pasażerów oraz ładunków w jednoosobowych i bezpilotowych statkach powietrznych\n",
        "- Znaczenie rozwoju technologii dla konkurencyjności pasażerskiego transportu lotniczego\n",
        "- ZMIANY W KONSTRUKCJACH I WYPOSAŻENIU CYWILNYCH STATKÓW PASAŻERSKICH W KONTEKŚCIE ZWIĘKSZENIA BEZPIECZEŃSTWA …\n",
        "\n",
        "Teraz wczytanie artykułów na temat samolotów z dysku i podział na fragmenty"
      ],
      "metadata": {
        "id": "guEgFoe8quXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_dir = \"/content/drive/MyDrive/Colab Notebooks/\"\n",
        "\n",
        "file_paths = [\n",
        "    os.path.join(pdf_dir, f)\n",
        "    for f in os.listdir(pdf_dir)\n",
        "    if f.lower().endswith(\".pdf\")\n",
        "]\n",
        "\n",
        "all_docs = []\n",
        "\n",
        "for file_path in file_paths:\n",
        "    file = Path(file_path)\n",
        "    if file.is_file():\n",
        "        try:\n",
        "            loader = PyPDFLoader(file_path)\n",
        "            docs = loader.load()\n",
        "\n",
        "            print(f\"Załadowano {len(docs)} stron(y) z pliku: {file.name}\")\n",
        "\n",
        "            all_docs.extend(docs)\n",
        "        except Exception as e:\n",
        "            print(f\"Błąd podczas ładowania pliku {file.name}: {e}\")\n",
        "    else:\n",
        "        print(f\"Plik nie znaleziony: {file_path}\")\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,\n",
        "    chunk_overlap=100,\n",
        "    length_function=len,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
        ")\n",
        "\n",
        "docs = text_splitter.split_documents(all_docs)\n",
        "\n",
        "print(f\"\\nŁączna liczba stron załadowana: {len(all_docs)}\")\n",
        "print(f\"Łączna liczba dokumentów po podziale: {len(docs)}\")\n"
      ],
      "metadata": {
        "id": "GwN3r2qIqzUK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa6f108e-f95e-4d0e-8cff-4a8d3f533c75"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Załadowano 24 stron(y) z pliku: Pre _Szwagrzyk_W poszukiwaniu_1_2015_JoTL.pdf\n",
            "Załadowano 270 stron(y) z pliku: strona bezpieczenstwo przewozu www.pdf\n",
            "Załadowano 26 stron(y) z pliku: Zmiany_w_konstrukcjach_i_wyposażeni.pdf\n",
            "Załadowano 23 stron(y) z pliku: Znaczenie_rozwoju_technologii_dla_k.pdf\n",
            "\n",
            "Łączna liczba stron załadowana: 343\n",
            "Łączna liczba dokumentów po podziale: 1994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stworzenie bazy wektorowej"
      ],
      "metadata": {
        "id": "6LcK3o-wswBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model_name = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
        "embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
        "index_dir = \"faiss_index_working\"\n",
        "db = FAISS.from_documents(docs, embeddings)\n",
        "db.save_local(index_dir)"
      ],
      "metadata": {
        "id": "7qKwdsNfsx7h"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicjalizacja modelu Q&A"
      ],
      "metadata": {
        "id": "lgS8pzPFs00P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa_model_name = \"google/flan-t5-large\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(qa_model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(qa_model_name)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "custom_prompt = (\n",
        "    \"Answer the question based only on the following context. If you cannot find the answer in the context, say that I cannot find the answer.'\\n\\n\"\n",
        "    \"Context: {context}\\n\\n\"\n",
        "    \"Question: {question}\\n\\n\"\n",
        "    \"Answer:\"\n",
        ")\n",
        "\n",
        "K = 3\n",
        "MAX_TOKENS = 512\n",
        "\n",
        "print(\"Type 'exit/quit/bye/goodbye' to exit\\n\")\n",
        "\n",
        "while True:\n",
        "    query = input(\"\\nWrite your question: \").strip()\n",
        "    if query.lower() in [\"exit\", \"quit\", \"bye\", \"goodbye\"]:\n",
        "        print(\"See ya!\")\n",
        "        break\n",
        "    if not query:\n",
        "        print(\"Question cannot be empty.\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        retrieved_docs = db.similarity_search(query, k=K)\n",
        "\n",
        "        context_parts = []\n",
        "        source_citations = []\n",
        "\n",
        "        for i, d in enumerate(retrieved_docs):\n",
        "            content = (d.page_content or \"\").strip()\n",
        "            context_parts.append(content)\n",
        "\n",
        "            source = d.metadata.get('source', 'Unknown')\n",
        "            page = d.metadata.get('page', 'Unknown page')\n",
        "            citation_info = {\n",
        "                'doc_number': i + 1,\n",
        "                'source_name': os.path.basename(source) if source != 'Unknown' else 'Unknown',\n",
        "                'page_number': page,\n",
        "                'content_preview': content[:100] + '...' if len(content) > 100 else content\n",
        "            }\n",
        "            source_citations.append(citation_info)\n",
        "\n",
        "        context = \"\\n\\n\".join(context_parts)\n",
        "\n",
        "        prompt_text = custom_prompt.format(context=context, question=query)\n",
        "\n",
        "        inputs = tokenizer(prompt_text, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=MAX_TOKENS,\n",
        "                do_sample=False,\n",
        "                temperature=0.1\n",
        "            )\n",
        "\n",
        "        answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        print(f\"AI Assistant:\")\n",
        "        print(f\"{answer}\\n\")\n",
        "\n",
        "        if retrieved_docs and source_citations:\n",
        "            print(f\"Sources used:\")\n",
        "\n",
        "            for citation in source_citations:\n",
        "                print(f\"[{citation['doc_number']}] {citation['source_name']}\")\n",
        "                print(f\"Page: {citation['page_number']}\")\n",
        "                print(f\"Excerpt: {citation['content_preview']}\")\n",
        "\n",
        "            print(f\"\\nCitation:\")\n",
        "            for citation in source_citations:\n",
        "                if citation['source_name'] != 'Unknown':\n",
        "                    print(f\"   [{citation['doc_number']}] {citation['source_name']}, p. {citation['page_number']}\")\n",
        "\n",
        "        elif not retrieved_docs:\n",
        "            print(\"No relevant documents found in the database.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing question: {e}\")\n",
        "        print(\"Try again with a different question.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuHVn6fNxf8C",
        "outputId": "17d8183a-2f38-4304-841a-93c7b9ad3f58"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type 'exit/quit/bye/goodbye' to exit\n",
            "\n",
            "\n",
            "Write your question: Ile samolotów pasażerskich dostarczył Airbus w 2014 roku i jak ta liczba wypadała w porównaniu z Boeingiem?\n",
            "AI Assistant:\n",
            "626\n",
            "\n",
            "Sources used:\n",
            "[1] Pre _Szwagrzyk_W poszukiwaniu_1_2015_JoTL.pdf\n",
            "Page: 9\n",
            "Excerpt: (źródło: opracowanie własne na podstawie [7])\n",
            "Obecnie w roku 2015, począwszy od 1 stycznia do dnia 3...\n",
            "[2] Pre _Szwagrzyk_W poszukiwaniu_1_2015_JoTL.pdf\n",
            "Page: 7\n",
            "Excerpt: nie. W ostatnich latach, można zaobserwować również większy popyt na\n",
            "produkty Airbusa, gdyż dostarcz...\n",
            "[3] Pre _Szwagrzyk_W poszukiwaniu_1_2015_JoTL.pdf\n",
            "Page: 16\n",
            "Excerpt: lat 2005-2014 z udziałem samolotów pochodzących od 2 największych\n",
            "producentów samolotów pasażerskich...\n",
            "\n",
            "Citation format:\n",
            "   [1] Pre _Szwagrzyk_W poszukiwaniu_1_2015_JoTL.pdf, p. 9\n",
            "   [2] Pre _Szwagrzyk_W poszukiwaniu_1_2015_JoTL.pdf, p. 7\n",
            "   [3] Pre _Szwagrzyk_W poszukiwaniu_1_2015_JoTL.pdf, p. 16\n",
            "\n",
            "Write your question: Jakie są główne zalety i charakterystyka samolotów rodziny A320 firmy Airbus?\n",
            "AI Assistant:\n",
            "I cannot find the answer.\n",
            "\n",
            "Sources used:\n",
            "[1] Znaczenie_rozwoju_technologii_dla_k.pdf\n",
            "Page: 11\n",
            "Excerpt: Źródło: opracowanie własne na podstawie Pisarek-Bartoszewska, 2020: 136.\n",
            "Bardzo wyraźnie widać, że s...\n",
            "[2] Pre _Szwagrzyk_W poszukiwaniu_1_2015_JoTL.pdf\n",
            "Page: 5\n",
            "Excerpt: Planowaną przez Airbusa odpowiedzią w wyścigu technologicznym\n",
            "lotniczych gigantów jest wprowadzenie ...\n",
            "[3] Znaczenie_rozwoju_technologii_dla_k.pdf\n",
            "Page: 10\n",
            "Excerpt: Linie lotnicze skupiają swoją flotę wokół jednego modelu lub określonej rodziny \n",
            "samolotów. Taką opc...\n",
            "\n",
            "Citation format:\n",
            "   [1] Znaczenie_rozwoju_technologii_dla_k.pdf, p. 11\n",
            "   [2] Pre _Szwagrzyk_W poszukiwaniu_1_2015_JoTL.pdf, p. 5\n",
            "   [3] Znaczenie_rozwoju_technologii_dla_k.pdf, p. 10\n",
            "\n",
            "Write your question: Co to jest ekranoplan i jakie są jego główne charakterystyki oraz zastosowania?\n",
            "AI Assistant:\n",
            "I cannot find the answer.\n",
            "\n",
            "Sources used:\n",
            "[1] Pre _Szwagrzyk_W poszukiwaniu_1_2015_JoTL.pdf\n",
            "Page: 5\n",
            "Excerpt: stępnych na rynku jest wspomniane już zainstalowanie na pokładzie licz-\n",
            "nych udogodnień dla pasażeró...\n",
            "[2] strona bezpieczenstwo przewozu www.pdf\n",
            "Page: 68\n",
            "Excerpt: znawanie scen, zapewniając bogatszy zestaw danych do analizy. Kamery te są wszechstronnymi \n",
            "narzędzi...\n",
            "[3] strona bezpieczenstwo przewozu www.pdf\n",
            "Page: 67\n",
            "Excerpt: nie ruchu obiektów lub ludzi w czasie rzeczywistym, co jest przydatne w monitoringu wizyjnym, \n",
            "anali...\n",
            "\n",
            "Citation format:\n",
            "   [1] Pre _Szwagrzyk_W poszukiwaniu_1_2015_JoTL.pdf, p. 5\n",
            "   [2] strona bezpieczenstwo przewozu www.pdf, p. 68\n",
            "   [3] strona bezpieczenstwo przewozu www.pdf, p. 67\n",
            "\n",
            "Write your question: bye\n",
            "See ya!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tu przykład, że wskazał dobrze:\n",
        "\n",
        "Write your question: Ile samolotów pasażerskich dostarczył Airbus w 2014 roku i jak ta liczba wypadała w porównaniu z Boeingiem?\n",
        "\n",
        "AI Assistant:\n",
        "626\n",
        "\n",
        "Sources used:\n",
        "\n",
        "[1] Pre _Szwagrzyk_W poszukiwaniu_1_2015_JoTL.pdf\n",
        "Page: 9\n",
        "\n",
        "Excerpt: (źródło: opracowanie własne na podstawie [7])\n",
        "Obecnie w roku 2015, począwszy od 1 stycznia do dnia 3...\n",
        "\n",
        "[2] Pre _Szwagrzyk_W poszukiwaniu_1_2015_JoTL.pdf\n",
        "Page: 7\n",
        "\n",
        "Excerpt: nie. W ostatnich latach, można zaobserwować również większy popyt na\n",
        "produkty Airbusa, gdyż dostarcz...\n",
        "\n",
        "[3] Pre _Szwagrzyk_W poszukiwaniu_1_2015_JoTL.pdf\n",
        "Page: 16\n",
        "\n",
        "Excerpt: lat 2005-2014 z udziałem samolotów pochodzących od 2 największych\n",
        "producentów samolotów pasażerskich...\n",
        "\n",
        "Citation format:\n",
        "\n",
        "   [1] Pre _Szwagrzyk_W poszukiwaniu_1_2015_JoTL.pdf, p. 9\n",
        "\n",
        "   [2] Pre _Szwagrzyk_W poszukiwaniu_1_2015_JoTL.pdf, p. 7\n",
        "\n",
        "   [3] Pre _Szwagrzyk_W poszukiwaniu_1_2015_JoTL.pdf, p. 16\n",
        "\n",
        "====================================================================\n",
        "\n",
        "Tu ciekawe, bo wskazał w 1. źródle dobry pdf i dobrą stronę, ale nie znalazł odpowiedzi XD\n",
        "\n",
        "Write your question: Jakie są główne zalety i charakterystyka samolotów rodziny A320 firmy Airbus?\n",
        "\n",
        "AI Assistant:\n",
        "I cannot find the answer.\n",
        "\n",
        "Sources used:\n",
        "\n",
        "[1] Znaczenie_rozwoju_technologii_dla_k.pdf\n",
        "Page: 11\n",
        "\n",
        "Excerpt: Źródło: opracowanie własne na podstawie Pisarek-Bartoszewska, 2020: 136.\n",
        "Bardzo wyraźnie widać, że s...\n",
        "\n",
        "[2] Pre _Szwagrzyk_W poszukiwaniu_1_2015_JoTL.pdf\n",
        "Page: 5\n",
        "\n",
        "Excerpt: Planowaną przez Airbusa odpowiedzią w wyścigu technologicznym\n",
        "lotniczych gigantów jest wprowadzenie ...\n",
        "\n",
        "[3] Znaczenie_rozwoju_technologii_dla_k.pdf\n",
        "Page: 10\n",
        "\n",
        "Excerpt: Linie lotnicze skupiają swoją flotę wokół jednego modelu lub określonej rodziny\n",
        "samolotów. Taką opc...\n",
        "\n",
        "Citation format:\n",
        "\n",
        "   [1] Znaczenie_rozwoju_technologii_dla_k.pdf, p. 11\n",
        "\n",
        "   [2] Pre _Szwagrzyk_W poszukiwaniu_1_2015_JoTL.pdf, p. 5\n",
        "\n",
        "   [3] Znaczenie_rozwoju_technologii_dla_k.pdf, p. 10\n",
        "\n",
        "======================================================\n",
        "\n",
        "Write your question: bye\n",
        "\n",
        "See ya!\n",
        "\n",
        ":)"
      ],
      "metadata": {
        "id": "dJd0aSzyg3XM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fun fact: próbowałem użyć radlab oraz retrievala i pokazało mi, że nie jest publiczny XD"
      ],
      "metadata": {
        "id": "nmy08iSbg7vr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Długo się z tym męczyłem, ale się wiele nauczyłem za to :))"
      ],
      "metadata": {
        "id": "U-b9tCU3hF5K"
      }
    }
  ]
}